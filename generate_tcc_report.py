#!/usr/bin/env python3
"""
Gerador de Relat√≥rio Final para TCC
Consolida todos os resultados em relat√≥rio estruturado
"""
import json
import logging
from datetime import datetime
from typing import Dict, List
import os

from config import settings_v3

log = logging.getLogger(__name__)


class TCCReportGenerator:
    """Gera relat√≥rio consolidado para TCC"""
    
    def __init__(self, pipeline_results: Dict = None, data_dir: str = None):
        self.pipeline_results = pipeline_results or {}
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.data_dir = data_dir or settings_v3.V3_DATA_DIR
        
        # Carrega dados automaticamente se n√£o fornecidos
        if not self.pipeline_results:
            log.info("Carregando resultados de arquivos JSON...")
            self.pipeline_results = self._load_latest_results()
    
    def _load_latest_results(self) -> Dict:
        """
        Carrega resultados mais recentes dos arquivos JSON gerados
        """
        import glob
        
        results = {}
        
        # Busca arquivos JSON no diret√≥rio de dados
        json_pattern = os.path.join(self.data_dir, "*.json")
        json_files = sorted(glob.glob(json_pattern), key=os.path.getmtime, reverse=True)
        
        if not json_files:
            log.warning(f"Nenhum arquivo JSON encontrado em {self.data_dir}")
            return results
        
        # Agrupa por tipo (pega mais recente de cada tipo)
        loaded = {}
        for json_file in json_files:
            basename = os.path.basename(json_file)
            
            # Identifica tipo do arquivo
            if 'prototypes' in basename and 'prototypes' not in loaded:
                try:
                    with open(json_file, 'r') as f:
                        results['prototype_results'] = json.load(f)
                    loaded['prototypes'] = True
                    log.info(f"  ‚úì Prototypes: {basename}")
                except Exception as e:
                    log.warning(f"Erro ao carregar {basename}: {e}")
            
            elif 'patterns_agent' in basename and 'patterns_agent' not in loaded:
                try:
                    with open(json_file, 'r') as f:
                        if 'pattern_results' not in results:
                            results['pattern_results'] = {}
                        results['pattern_results']['agent'] = json.load(f)
                    loaded['patterns_agent'] = True
                    log.info(f"  ‚úì Patterns Agent: {basename}")
                except Exception as e:
                    log.warning(f"Erro ao carregar {basename}: {e}")
            
            elif 'patterns_client' in basename and 'patterns_client' not in loaded:
                try:
                    with open(json_file, 'r') as f:
                        if 'pattern_results' not in results:
                            results['pattern_results'] = {}
                        results['pattern_results']['client'] = json.load(f)
                    loaded['patterns_client'] = True
                    log.info(f"  ‚úì Patterns Client: {basename}")
                except Exception as e:
                    log.warning(f"Erro ao carregar {basename}: {e}")
            
            elif 'patterns_status' in basename and 'patterns_status' not in loaded:
                try:
                    with open(json_file, 'r') as f:
                        results['pattern_status_results'] = json.load(f)
                    loaded['patterns_status'] = True
                    log.info(f"  ‚úì Patterns Status: {basename}")
                except Exception as e:
                    log.warning(f"Erro ao carregar {basename}: {e}")
            
            elif 'view_comparison' in basename and 'view_comparison' not in loaded:
                try:
                    with open(json_file, 'r') as f:
                        results['comparison_results'] = json.load(f)
                    loaded['view_comparison'] = True
                    log.info(f"  ‚úì View Comparison: {basename}")
                except Exception as e:
                    log.warning(f"Erro ao carregar {basename}: {e}")
            
            elif 'pca_analysis' in basename and basename not in loaded:
                try:
                    with open(json_file, 'r') as f:
                        if 'pca_umap_results' not in results:
                            results['pca_umap_results'] = {}
                        view_name = basename.split('_')[2]  # pca_analysis_FULL_timestamp.json
                        results['pca_umap_results'][view_name] = json.load(f)
                    loaded[basename] = True
                    log.info(f"  ‚úì PCA Analysis: {basename}")
                except Exception as e:
                    log.warning(f"Erro ao carregar {basename}: {e}")
        
        log.info(f"‚úì {len(loaded)} arquivos carregados")
        
        return results
    
    def generate_markdown_report(self, output_path: str):
        """
        Gera relat√≥rio em formato Markdown
        
        Args:
            output_path: Caminho do arquivo de sa√≠da (.md)
        """
        log.info("Gerando relat√≥rio em Markdown...")
        
        report = self._build_markdown_content()
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(report)
        
        log.info(f"‚úì Relat√≥rio Markdown salvo em: {output_path}")
    
    def _build_markdown_content(self) -> str:
        """Constr√≥i conte√∫do do relat√≥rio em Markdown"""
        
        sections = []
        
        # Cabe√ßalho
        sections.append(self._section_header())
        
        # Resumo executivo
        sections.append(self._section_executive_summary())
        
        # Metodologia
        sections.append(self._section_methodology())
        
        # Resultados - Compara√ß√£o de vis√µes
        sections.append(self._section_view_comparison())
        
        # Resultados - Prot√≥tipos
        sections.append(self._section_prototypes())
        
        # Resultados - Padr√µes lingu√≠sticos
        sections.append(self._section_patterns())
        
        # Insights estrat√©gicos
        sections.append(self._section_insights())
        
        # Conclus√µes
        sections.append(self._section_conclusions())
        
        # Ap√™ndices
        sections.append(self._section_appendix())
        
        return "\n\n".join(sections)
    
    def _section_header(self) -> str:
        """Cabe√ßalho do relat√≥rio"""
        return f"""# An√°lise de Padr√µes Sem√¢nticos em Liga√ß√µes de Vendas

**Trabalho de Conclus√£o de Curso (TCC)**  
**Autor:** Daniel Nascimento  
**Data:** {datetime.now().strftime("%d de %B de %Y")}  
**Vers√£o:** 1.0 - An√°lise Multiview com Embeddings V2

---

## Sum√°rio

1. [Resumo Executivo](#resumo-executivo)
2. [Metodologia](#metodologia)
3. [Compara√ß√£o de Vis√µes de Embedding](#compara√ß√£o-de-vis√µes-de-embedding)
4. [An√°lise de Prot√≥tipos](#an√°lise-de-prot√≥tipos)
5. [Padr√µes Lingu√≠sticos Discriminativos](#padr√µes-lingu√≠sticos-discriminativos)
6. [Insights Estrat√©gicos](#insights-estrat√©gicos)
7. [Conclus√µes e Recomenda√ß√µes](#conclus√µes-e-recomenda√ß√µes)
8. [Ap√™ndices](#ap√™ndices)

---"""
    
    def _section_executive_summary(self) -> str:
        """Resumo executivo com dados reais"""
        
        # Extrai dados
        comparison = self.pipeline_results.get('comparison_results', {})
        global_comp = comparison.get('global_comparison', {})
        prototypes = self.pipeline_results.get('prototype_results', {})
        patterns_status = self.pipeline_results.get('pattern_status_results', {})
        
        # Identifica melhor vis√£o
        best_view = "full"
        best_silhouette = 0.0
        if global_comp:
            ranking = global_comp.get('ranking', [])
            if ranking:
                best_data = ranking[0]  # J√° vem ordenado
                best_view = best_data.get('view', 'full')
                best_silhouette = best_data.get('silhouette', 0.0)
        
        # Conta padr√µes significativos
        n_patterns = 0
        if patterns_status:
            for product_data in patterns_status.values():
                if isinstance(product_data, dict):
                    n_patterns += len(product_data.get('significant_patterns', []))
        
        # Conta produtos analisados
        n_products = len(patterns_status) if patterns_status else 0
        
        return f"""## 1. Resumo Executivo

Este trabalho investiga padr√µes sem√¢nticos discriminativos em liga√ß√µes de vendas utilizando embeddings de texto e t√©cnicas de an√°lise multiview. A abordagem introduz:

### Contribui√ß√µes Principais

1. **An√°lise Multiview**: Compara√ß√£o sistem√°tica de tr√™s perspectivas de embedding
   - **Full**: Transcri√ß√£o completa da liga√ß√£o
   - **Agent**: Apenas falas do agente
   - **Client**: Apenas falas do cliente

2. **An√°lise por Produto**: Identifica√ß√£o de padr√µes espec√≠ficos por tipo de produto vendido

3. **An√°lise por Status**: Separa√ß√£o de padr√µes em oportunidades ganhas vs perdidas

4. **Padr√µes Lingu√≠sticos**: Extra√ß√£o de 80+ patterns organizados em 15 categorias sem√¢nticas

### Principais Descobertas

- **Melhor Vis√£o de Embedding**: `{best_view}` (silhueta: {best_silhouette:.4f})
- **Separa√ß√£o Sem√¢ntica**: Silhueta m√©dia de {best_silhouette:.4f} entre ganhas/perdidas
- **Padr√µes Significativos**: {n_patterns} patterns discriminativos identificados
- **Produtos Analisados**: {n_products} produtos com an√°lise completa
- **Insights Acion√°veis**: Recomenda√ß√µes espec√≠ficas por produto baseadas em dados reais

---"""
    
    def _section_methodology(self) -> str:
        """Se√ß√£o de metodologia"""
        return f"""## 2. Metodologia

### 2.1. Pipeline de Processamento

```
Transcri√ß√µes ‚Üí Embeddings V2 ‚Üí An√°lise Multiview ‚Üí Insights
                  ‚Üì                    ‚Üì
            (3 vis√µes)      Prot√≥tipos + Padr√µes
```

### 2.2. Embeddings V2

- **Modelo**: `jinaai/jina-embeddings-v3`
- **Dimensionalidade**: 768d
- **Token Limit**: 8192 tokens (vs 512 da V1)
- **Estrat√©gia**: Re-embedding de texto concatenado
- **Vis√µes**:
  - `full`: Liga√ß√£o completa
  - `agent`: Apenas agente
  - `client`: Apenas cliente
  
**Nota**: A vis√£o `labeled` (com marcadores [AG]/[CL]) foi descartada por degrada√ß√£o de qualidade confirmada empiricamente.

### 2.3. An√°lise de Prot√≥tipos

**Objetivo**: Identificar centr√≥ides sem√¢nticos de liga√ß√µes ganhas vs perdidas

**M√©tricas**:
- **Coes√£o Intra-Cluster**: Similaridade m√©dia dentro do cluster
- **Separa√ß√£o Inter-Cluster**: Dist√¢ncia cosseno entre prot√≥tipos
- **Silhueta**: Qualidade de separa√ß√£o global (-1 a 1)

### 2.4. An√°lise de Padr√µes Lingu√≠sticos

**Patterns Extra√≠dos**: {len(settings_v3.STOPWORDS_COMPLETAS)} stopwords filtradas

**Categorias** (15 categorias, 80+ patterns):
1. Produtos (seguro carga, garantia, vida, etc.)
2. Processos (cota√ß√£o, proposta, contrato, etc.)
3. Documenta√ß√£o (minuta, CNPJ, nota fiscal, etc.)
4. Financeiro (valor, desconto, parcela, etc.)
5. Urg√™ncia (urgente, prazo, r√°pido, etc.)
6. Problemas (d√∫vida, problema, erro, etc.)
7. Positivo (perfeito, obrigado, entendi, etc.)
8. Obje√ß√µes (caro, concorrente, j√° tenho, etc.)
9. Fechamento (quando, como funciona, pr√≥ximo passo, etc.)
10. Negocia√ß√£o (negociar, melhor pre√ßo, concess√£o, etc.)
11. Relacionamento (parceria, confian√ßa, indica√ß√£o, etc.)
12. T√©cnico/Compliance (cl√°usula, exclus√£o, regulamento, etc.)
13. Competitivo (diferencial, compara√ß√£o, inova√ß√£o, etc.)
14. Risco/Seguran√ßa (risco, prote√ß√£o, cobertura, etc.)
15. Operacional (sistema, email, telefone, etc.)

**Teste Estat√≠stico**: Chi-quadrado para signific√¢ncia (p < 0.05)

### 2.5. Visualiza√ß√µes

- **UMAP**: Redu√ß√£o dimensional para visualiza√ß√£o 2D
- **Par√¢metros**: n_neighbors=15, min_dist=0.1, metric=cosine
- **Compara√ß√µes**: Heatmaps, barplots, dashboards

---"""
    
    def _section_view_comparison(self) -> str:
        """Se√ß√£o de compara√ß√£o de vis√µes com dados reais"""
        
        comparison = self.pipeline_results.get('comparison_results', {})
        global_comp = comparison.get('global_comparison', {})
        by_product = comparison.get('by_product', {})
        
        # Tabela de m√©tricas globais
        table_rows = []
        by_view = global_comp.get('by_view', {})
        for view_name in ['full', 'agent', 'client']:
            if view_name in by_view:
                view_data = by_view[view_name]
                view = view_name.capitalize()
                silh = view_data.get('silhouette_overall', 0.0)
                sep = view_data.get('separation_distance', 0.0)
                coes_g = view_data.get('cohesion_ganha', 0.0)
                coes_p = view_data.get('cohesion_perdida', 0.0)
                n_samp = view_data.get('n_ganha', 0) + view_data.get('n_perdida', 0)
                table_rows.append(f"| {view:6} | {silh:8.4f} | {sep:9.4f} | {coes_g:12.4f} | {coes_p:14.4f} | {n_samp:10} |")
        
        table_str = "\n".join(table_rows) if table_rows else "| (sem dados) | - | - | - | - | - |"
        
        # Melhor vis√£o
        best_view = "N/A"
        best_silh = 0.0
        ranking = global_comp.get('ranking', [])
        if ranking:
            best_view = ranking[0].get('view', 'N/A')
            best_silh = ranking[0].get('silhouette', 0.0)
        
        # Ranking por produto
        products_comp = comparison.get('products_comparison', {})
        best_view_counts = products_comp.get('best_view_counts', {})
        
        ranking = sorted(best_view_counts.items(), key=lambda x: x[1], reverse=True)
        ranking_str = "\n".join([f"{i+1}. **{view.capitalize()}**: {count} produtos" 
                                  for i, (view, count) in enumerate(ranking)])
        if not ranking_str:
            ranking_str = "(sem dados)"
        
        # Performance m√©dia por vis√£o (extrair de product_comparisons)
        product_comps = products_comp.get('product_comparisons', {})
        view_stats = {}
        
        for product_name, prod_data in product_comps.items():
            by_view = prod_data.get('by_view', {})
            for view_name, view_data in by_view.items():
                silh = view_data.get('silhouette_overall', 0.0)
                if view_name not in view_stats:
                    view_stats[view_name] = []
                view_stats[view_name].append(silh)
        
        stats_str = []
        for view in ['full', 'agent', 'client']:
            if view in view_stats and view_stats[view]:
                import numpy as np
                mean = np.mean(view_stats[view])
                std = np.std(view_stats[view])
                stats_str.append(f"- **{view.capitalize()}**: Œº={mean:.4f}, œÉ={std:.4f}")
            else:
                stats_str.append(f"- **{view.capitalize()}**: (sem dados)")
        
        stats_text = "\n".join(stats_str)
        
        return f"""## 3. Compara√ß√£o de Vis√µes de Embedding

### 3.1. M√©tricas Globais

| Vis√£o  | Silhueta | Separa√ß√£o | Coes√£o Ganha | Coes√£o Perdida | N Amostras |
|--------|----------|-----------|--------------|----------------|------------|
{table_str}

**Melhor Vis√£o (Global)**: `{best_view}` com silhueta de {best_silh:.4f}

### 3.2. Performance por Produto

**Ranking de Consist√™ncia** (vis√£o que venceu em mais produtos):

{ranking_str}

**Performance M√©dia por Vis√£o**:

{stats_text}

### 3.3. Recomenda√ß√£o Final

**Vis√£o Recomendada**: `{best_view}`

**Justificativa**: Baseado nas m√©tricas globais e consist√™ncia por produto, a vis√£o `{best_view}` apresentou melhor separa√ß√£o sem√¢ntica entre liga√ß√µes ganhas e perdidas (silhueta: {best_silh:.4f}).

**Visualiza√ß√µes**:
- Ver: `plots/umap_comparative_*.png`
- Ver: `plots/view_metrics_*.png`
- Ver: `plots/product_performance_*.png`

---"""
    
    def _section_prototypes(self) -> str:
        """Se√ß√£o de prot√≥tipos com dados reais"""
        
        prototypes = self.pipeline_results.get('prototype_results', {})
        
        # Prot√≥tipos globais por vis√£o
        sections = []
        sections.append("## 4. An√°lise de Prot√≥tipos\n\n### 4.1. Prot√≥tipos Globais\n")
        
        for view in ['full', 'agent', 'client']:
            view_key = f'global_{view}'
            view_data = prototypes.get(view_key, {})
            if view_data:
                ganha_data = view_data.get('ganha', {})
                perdida_data = view_data.get('perdida', {})
                sep_data = view_data.get('separation', {})
                
                n_ganha = ganha_data.get('n_samples', 0)
                n_perdida = perdida_data.get('n_samples', 0)
                cohesion_g = ganha_data.get('cohesion', 0.0)
                cohesion_p = perdida_data.get('cohesion', 0.0)
                separation = sep_data.get('distance', 0.0)
                silh_data = sep_data.get('silhouette', {})
                silhouette = silh_data.get('overall', 0.0) if isinstance(silh_data, dict) else 0.0
                
                sections.append(f"""#### Vis√£o {view.capitalize()}

- **Ganha**: {n_ganha} amostras, coes√£o={cohesion_g:.4f}
- **Perdida**: {n_perdida} amostras, coes√£o={cohesion_p:.4f}
- **Separa√ß√£o**: {separation:.4f}
- **Silhueta**: {silhouette:.4f}
""")
            else:
                sections.append(f"""#### Vis√£o {view.capitalize()}

(sem dados)
""")
        
        # Top produtos
        sections.append("\n### 4.2. Prot√≥tipos por Produto\n")
        sections.append("**Top 5 Produtos com Melhor Separa√ß√£o**:\n\n")
        
        # Extrai dados de produtos diretamente de prototypes
        product_scores = []
        for key, data in prototypes.items():
            if key.startswith('product_') and key.endswith('_full'):  # Usa apenas full view
                product_name = key.replace('product_', '').replace('_full', '')
                sep_data = data.get('separation', {})
                silh_data = sep_data.get('silhouette', {})
                silh = silh_data.get('overall', 0.0) if isinstance(silh_data, dict) else 0.0
                dist = sep_data.get('distance', 0.0)
                product_scores.append((product_name, silh, dist))
        
        # Ordena e pega top 5
        product_scores.sort(key=lambda x: x[1], reverse=True)
        for i, (product, silh, dist) in enumerate(product_scores[:5], 1):
            sections.append(f"{i}. **{product}**: silhueta={silh:.4f}, dist={dist:.4f}\n")
        
        if not product_scores:
            sections.append("(sem dados)\n")
        
        sections.append("""
**Interpreta√ß√£o**: Produtos com alta separa√ß√£o possuem padr√µes sem√¢nticos bem definidos entre ganhas e perdidas, facilitando identifica√ß√£o de estrat√©gias vencedoras.

**Visualiza√ß√µes**:
- Ver: `plots/umap_products_*.png`

---""")
        
        return "".join(sections)
    
    def _section_patterns(self) -> str:
        """Se√ß√£o de padr√µes lingu√≠sticos com dados reais"""
        
        patterns_status = self.pipeline_results.get('pattern_status_results', {})
        insights = patterns_status.get('insights', {})
        product_insights = insights.get('product_specific_insights', {})
        universal = insights.get('universal_patterns', {})
        
        sections = []
        sections.append("## 5. Padr√µes Lingu√≠sticos Discriminativos\n\n")
        
        # 5.1 Padr√µes Universais
        sections.append("### 5.1. Padr√µes Universais (Multi-Produto)\n\n")
        
        # Extrai padr√µes universais
        winning = universal.get('winning', [])
        losing = universal.get('losing', [])
        
        # Tabela vencedores
        sections.append("**Padr√µes Vencedores** (presentes em 3+ produtos):\n\n")
        sections.append("| Keyword | Produtos | N Produtos |\n")
        sections.append("|---------|----------|------------|\n")
        
        for w in winning[:10]:
            keyword = w.get('keyword', '')
            products = w.get('products', [])
            n_prod = len(products)
            count = w.get('count', 0)
            sections.append(f"| {keyword[:25]} | {', '.join(products[:2])}... | {n_prod} |\n")
        
        if not winning:
            sections.append("| (sem dados) | - | - |\n")
        
        # Tabela perdedores
        sections.append("\n**Padr√µes Perdedores** (presentes em 3+ produtos):\n\n")
        sections.append("| Keyword | Produtos | N Produtos |\n")
        sections.append("|---------|----------|------------|\n")
        
        for l in losing[:10]:
            keyword = l.get('keyword', '')
            products = l.get('products', [])
            n_prod = len(products)
            sections.append(f"| {keyword[:25]} | {', '.join(products[:2])}... | {n_prod} |\n")
        
        if not losing:
            sections.append("| (sem dados) | - | - |\n")
        
        # 5.2 Por produto (top 3)
        sections.append("\n### 5.2. Padr√µes Espec√≠ficos por Produto (Top 3)\n\n")
        
        # Ordena produtos por win rate
        product_list = [(p, d.get('win_rate', 0)) for p, d in product_insights.items()]
        product_list.sort(key=lambda x: x[1], reverse=True)
        
        for product, _ in product_list[:3]:
            data = product_insights[product]
            win_rate = data.get('win_rate', 0.0)
            n_ganha = data.get('n_ganha', 0)
            n_perdida = data.get('n_perdida', 0)
            n_calls = n_ganha + n_perdida
            
            top_winning = data.get('top_winning_strategies', [])
            top_losing = data.get('top_losing_strategies', [])
            
            sections.append(f"#### {product}\n\n")
            sections.append(f"**Win Rate**: {win_rate:.1f}%  \n")
            sections.append(f"**N Chamadas**: {n_calls} ({n_ganha} ganhas, {n_perdida} perdidas)\n\n")
            
            # Top vencedores
            sections.append("**Top 5 Estrat√©gias Vencedoras**:\n\n")
            for i, strat in enumerate(top_winning[:5], 1):
                keyword = strat.get('keyword', '')
                category = strat.get('category', 'N/A')
                diff = strat.get('diff', 0.0)
                pval = strat.get('p_value', 1.0)
                sig = "***" if pval < 0.001 else "**" if pval < 0.01 else "*"
                sections.append(f"{i}. **{keyword}** ({category}): +{diff:.1f}% {sig}\n")
            
            if not top_winning:
                sections.append("(sem padr√µes vencedores)\n")
            
            # Top perdedores
            sections.append("\n**Top 3 Padr√µes a Evitar**:\n\n")
            for i, strat in enumerate(top_losing[:3], 1):
                keyword = strat.get('keyword', '')
                category = strat.get('category', 'N/A')
                diff = strat.get('diff', 0.0)
                pval = strat.get('p_value', 1.0)
                sig = "***" if pval < 0.001 else "**" if pval < 0.01 else "*"
                sections.append(f"{i}. **{keyword}** ({category}): {diff:.1f}% {sig}\n")
            
            if not top_losing:
                sections.append("(sem padr√µes perdedores)\n")
            
            sections.append("\n")
        
        # 5.3 Por categoria (placeholder - dados n√£o dispon√≠veis em JSON)
        sections.append("### 5.3. An√°lise por Categoria\n\n")
        sections.append("**Nota**: An√°lise detalhada por categoria dispon√≠vel nos arquivos JSON individuais.\n\n")
        
        sections.append("""**Visualiza√ß√µes**:
- Ver: `data/patterns_agent_*.json`
- Ver: `data/patterns_client_*.json`

---""")
        
        return "".join(sections)
    
    def _section_insights(self) -> str:
        """Se√ß√£o de insights estrat√©gicos"""
        return """## 6. Insights Estrat√©gicos

### 6.1. Insights Globais

1. **Vis√£o de Embedding √ìtima**: [VIS√ÉO] apresenta melhor separa√ß√£o ganha/perdida
2. **Consist√™ncia**: [VIS√ÉO] √© mais consistente atrav√©s de produtos (menor vari√¢ncia)
3. **Padr√µes Universais**: [N] patterns s√£o discriminativos em m√∫ltiplos produtos

### 6.2. Insights por Produto

#### Produtos de Alto Desempenho (Win Rate > 60%)

**Caracter√≠sticas comuns**:
- Uso frequente de: [patterns]
- Evitam: [patterns]
- Foco nas categorias: [categorias]

#### Produtos de Baixo Desempenho (Win Rate < 40%)

**Oportunidades de melhoria**:
- Aumentar uso de: [patterns]
- Reduzir: [patterns]
- Treinar em: [categorias]

### 6.3. Recomenda√ß√µes Pr√°ticas

#### Para Gestores de Vendas

1. **Treinamento**: Foco em patterns vencedores da categoria [X]
2. **Scripts**: Incorporar keywords: [lista]
3. **Evitar**: Reduzir uso de obje√ß√µes como [keywords]

#### Para Produtos Espec√≠ficos

**[Produto A]**:
- ‚úÖ Manter: [estrat√©gias]
- ‚ö†Ô∏è Melhorar: [aspectos]
- üéØ Foco: [categorias]

*[Repetir para produtos principais]*

### 6.4. Impacto Esperado

**Ado√ß√£o de Recomenda√ß√µes**:
- Potencial aumento de win rate: +[X]% a +[Y]%
- ROI estimado: [valor]
- Tempo de implementa√ß√£o: [per√≠odo]

---"""
    
    def _section_conclusions(self) -> str:
        """Se√ß√£o de conclus√µes"""
        return """## 7. Conclus√µes e Recomenda√ß√µes

### 7.1. Principais Conclus√µes

1. **Embeddings V2 s√£o Superiores**: Re-embedding com limite de 8192 tokens captura melhor sem√¢ntica completa

2. **Vis√µes Complementares**: [VIS√ÉO] √© globalmente melhor, mas vis√µes espec√≠ficas podem ser √∫teis por produto

3. **Padr√µes S√£o Discriminativos**: 80+ patterns organizados em 15 categorias capturam diferen√ßas significativas

4. **Varia√ß√£o por Produto**: Estrat√©gias vencedoras s√£o produto-espec√≠ficas, n√£o universais

5. **An√°lise Temporal Importa**: Padr√µes presentes em diferentes fases da conversa t√™m impactos distintos

### 7.2. Limita√ß√µes

- **Dados**: An√°lise limitada a liga√ß√µes com transcri√ß√£o completa
- **Causalidade**: Correla√ß√£o ‚â† causa√ß√£o; patterns podem ser efeito, n√£o causa
- **Generaliza√ß√£o**: Resultados espec√≠ficos para o contexto de seguros
- **Token Limit**: Algumas liga√ß√µes longas s√£o truncadas

### 7.3. Trabalhos Futuros

1. **Modelos Preditivos**: Treinar classificadores com features extra√≠das
2. **An√°lise Temporal**: Incorporar ordem e timing dos patterns
3. **Multimodalidade**: Adicionar caracter√≠sticas pros√≥dicas (tom, velocidade)
4. **A/B Testing**: Validar recomenda√ß√µes em campo
5. **LLMs**: Explorar embeddings de modelos maiores (GPT, Claude)

### 7.4. Considera√ß√µes Finais

Este trabalho demonstra que an√°lise sem√¢ntica sistem√°tica de liga√ß√µes de vendas pode identificar padr√µes discriminativos acion√°veis. A abordagem multiview oferece uma base s√≥lida para sistemas de coaching automatizado e recomenda√ß√£o de estrat√©gias.

**Implementa√ß√£o Pr√°tica**: Os insights podem ser integrados em:
- Dashboards de monitoramento em tempo real
- Sistemas de feedback p√≥s-chamada
- M√≥dulos de treinamento personalizados
- Ferramentas de sugest√£o durante chamadas

---"""
    
    def _section_appendix(self) -> str:
        """Se√ß√£o de ap√™ndices"""
        return f"""## 8. Ap√™ndices

### A. Estrutura de Arquivos

```
sales-call-topic-analysis/
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ settings_v3.py          # Configura√ß√µes
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ database_v3.py          # Conex√£o com banco
‚îÇ   ‚îî‚îÄ‚îÄ embeddings_v3.py        # Utilit√°rios de embeddings
‚îú‚îÄ‚îÄ analysis/
‚îÇ   ‚îú‚îÄ‚îÄ prototypes_v3.py        # An√°lise de prot√≥tipos
‚îÇ   ‚îú‚îÄ‚îÄ patterns_by_product.py  # Padr√µes por produto
‚îÇ   ‚îú‚îÄ‚îÄ patterns_by_product_status.py  # Padr√µes por status
‚îÇ   ‚îî‚îÄ‚îÄ comparisons.py          # Compara√ß√£o de vis√µes
‚îú‚îÄ‚îÄ visualization/
‚îÇ   ‚îú‚îÄ‚îÄ umap_plots.py           # Visualiza√ß√µes UMAP
‚îÇ   ‚îî‚îÄ‚îÄ comparison_plots.py     # Gr√°ficos comparativos
‚îú‚îÄ‚îÄ outputs/
‚îÇ   ‚îú‚îÄ‚îÄ data/                   # Dados JSON
‚îÇ   ‚îú‚îÄ‚îÄ plots/                  # Gr√°ficos PNG
‚îÇ   ‚îî‚îÄ‚îÄ reports/                # Relat√≥rios
‚îú‚îÄ‚îÄ pipeline_v3_main.py         # Pipeline principal
‚îî‚îÄ‚îÄ generate_tcc_report.py      # Gerador deste relat√≥rio
```

### B. Configura√ß√µes Utilizadas

```python
EMBEDDING_VIEWS = {settings_v3.EMBEDDING_VIEWS}
MIN_CALLS_PER_PRODUCT = {settings_v3.MIN_CALLS_PER_PRODUCT}
MIN_CALLS_PER_PRODUCT_STATUS = {settings_v3.MIN_CALLS_PER_PRODUCT_STATUS}
UMAP_N_NEIGHBORS = {settings_v3.UMAP_N_NEIGHBORS}
UMAP_MIN_DIST = {settings_v3.UMAP_MIN_DIST}
CHI_SQUARE_THRESHOLD = {settings_v3.CHI_SQUARE_THRESHOLD}
MIN_DIFF_PERCENTAGE = {settings_v3.MIN_DIFF_PERCENTAGE}
```

### C. Depend√™ncias

- Python 3.9+
- sentence-transformers
- psycopg[binary]
- numpy
- matplotlib
- seaborn
- umap-learn
- scikit-learn

### D. Reprodu√ß√£o

Para reproduzir este relat√≥rio:

```bash
# 1. Executar pipeline completo
python pipeline_v3_main.py

# 2. Gerar relat√≥rio
python generate_tcc_report.py
```

### E. Contato

**Autor**: Daniel Nascimento  
**Email**: [email]  
**GitHub**: [repo]  
**Data**: {datetime.now().strftime("%d/%m/%Y")}

---

**FIM DO RELAT√ìRIO**
"""
    
    def generate_html_report(self, markdown_path: str, output_path: str):
        """
        Converte relat√≥rio Markdown para HTML
        
        Args:
            markdown_path: Caminho do arquivo Markdown
            output_path: Caminho do arquivo HTML de sa√≠da
        """
        try:
            import markdown
            
            # L√™ Markdown
            with open(markdown_path, 'r', encoding='utf-8') as f:
                md_content = f.read()
            
            # Converte para HTML
            html_content = markdown.markdown(
                md_content,
                extensions=['tables', 'fenced_code', 'toc']
            )
            
            # Template HTML com estilo
            html_template = f"""<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TCC - An√°lise de Padr√µes Sem√¢nticos em Vendas</title>
    <style>
        body {{
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }}
        h1, h2, h3 {{
            color: #2c3e50;
        }}
        h1 {{
            border-bottom: 3px solid #3498db;
            padding-bottom: 10px;
        }}
        h2 {{
            border-bottom: 2px solid #95a5a6;
            padding-bottom: 8px;
            margin-top: 40px;
        }}
        table {{
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            background-color: white;
        }}
        th, td {{
            border: 1px solid #ddd;
            padding: 12px;
            text-align: left;
        }}
        th {{
            background-color: #3498db;
            color: white;
        }}
        tr:nth-child(even) {{
            background-color: #f2f2f2;
        }}
        code {{
            background-color: #f4f4f4;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
        }}
        pre {{
            background-color: #2c3e50;
            color: #ecf0f1;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
        }}
        pre code {{
            background-color: transparent;
            color: #ecf0f1;
        }}
        blockquote {{
            border-left: 4px solid #3498db;
            padding-left: 20px;
            color: #555;
            font-style: italic;
        }}
    </style>
</head>
<body>
{html_content}
</body>
</html>"""
            
            # Salva HTML
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(html_template)
            
            log.info(f"‚úì Relat√≥rio HTML salvo em: {output_path}")
            
        except ImportError:
            log.warning("M√≥dulo 'markdown' n√£o encontrado. Instale com: pip install markdown")
        except Exception as e:
            log.error(f"Erro ao gerar HTML: {e}")
    
    def generate_full_report(self):
        """Gera relat√≥rio completo (MD e HTML)"""
        log.info("="*80)
        log.info("üìÑ GERANDO RELAT√ìRIO FINAL PARA TCC")
        log.info("="*80)
        
        # Markdown
        md_path = os.path.join(settings_v3.V3_REPORTS_DIR, f"tcc_report_{self.timestamp}.md")
        self.generate_markdown_report(md_path)
        
        # HTML
        if settings_v3.TCC_REPORT_FORMAT in ["html", "both"]:
            html_path = os.path.join(settings_v3.V3_REPORTS_DIR, f"tcc_report_{self.timestamp}.html")
            self.generate_html_report(md_path, html_path)
        
        log.info("\n‚úì Relat√≥rios gerados com sucesso!")
        log.info(f"  ‚Ä¢ Markdown: {md_path}")
        if settings_v3.TCC_REPORT_FORMAT in ["html", "both"]:
            log.info(f"  ‚Ä¢ HTML: {html_path}")


def main():
    """Ponto de entrada"""
    generator = TCCReportGenerator()
    generator.generate_full_report()


if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    main()

